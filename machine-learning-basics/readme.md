Machine Learning es la capacidad de las computadoras de aprender a resolver problemas o dar soluciones apróximdas, sin ser explícitamente programadas para resolver dicho problema.

En machine learning el programa recibe datos en vez de instrucciones.

Machine Learning empieza con el Teorema de Bayes.
El Tearema de Bayes nos permite incorporar conocimiento o experiencia nueva adquirida al procesamiento del calculo de nuevas probabilidades, dadas los eventos anteriores.

Un elemento presente en la mayoría de algoritmos de machine learning, son los features vectores. Los features vectors son un mecanismo para combertir lo que conocemos o percibimos en el mundo real (que al final del día, serán los datos de aprendizaje del algoritmo) en valores numéricos que puedan ser utilizados como insumos del computo. 

Por ejemplo representar colores con RGB.

El reto en esta fase es definir cuales son los aspectos relevantes para el algoritmos y cuales no.

Se debe intentar varias veces, que valores se tienen que incluir y que valores se deben obviar o dejar por fuera. Siguiendo el principio de GIGO (garbage in, garbage out) es importante seleccionar bien los datos e incluso depurar datos encontrados.

Otro elemento base de machine learning son las métricas distancia entre vectores, las cuales nos permiten tener una forma de cuantificar que tan cercanos o lejanos estan los vectores que estamos incorporando al algoritmo.
Esto conceptualmente nos puede permitir estimar que tan igual o que tan diferentes son los datos con los que se está alimentando el algoritmo.

En un algoritmo de optimización, se busca optimizar la distancia entre vectores.

Las distancias se miden de varias formas, por ejemplo la forma Euclidiana, la forma de Manhattan.